{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7DYtXXEpbN5",
        "outputId": "96df63a8-f96d-4cd0-af16-acb06fc80ed8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSvZTSEwu4Zq",
        "outputId": "6a0380af-9eb7-4c6b-98fc-1594ba37abd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGiyCnvnu4b1",
        "outputId": "4b82b6ac-262a-44a8-891b-c04c72ce8ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting recordclass\n",
            "  Downloading recordclass-0.17.2.tar.gz (446 kB)\n",
            "\u001b[K     |████████████████████████████████| 446 kB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: recordclass\n",
            "  Building wheel for recordclass (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for recordclass: filename=recordclass-0.17.2-cp37-cp37m-linux_x86_64.whl size=288786 sha256=1b900175ab84ea223686d31d9154effdb22d43e5ab9b6b40dbb32b25bebd9ce6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/a7/f2/f1b5af34322f1cc71e5a877d03056a188728509fcadf683197\n",
            "Successfully built recordclass\n",
            "Installing collected packages: recordclass\n",
            "Successfully installed recordclass-0.17.2\n"
          ]
        }
      ],
      "source": [
        "!pip install recordclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USedg_tIu4eF",
        "outputId": "ec32bcbe-e246-4c68-8821-b40e239bea71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.32-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2022.6.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (4.1.1)\n",
            "Collecting botocore<1.28.0,>=1.27.32\n",
            "  Downloading botocore-1.27.32-py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.32->boto3->pytorch_transformers) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.32->boto3->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2022.6.15)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=4b6ac46bf5e911906c2e8e58808084adc6b5d3549b86890b12372573221fc0c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.24.32 botocore-1.27.32 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcqOwC-mu4kU",
        "outputId": "c9481895-1315-434e-f1df-fdd5c80b15dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "/content/drive/MyDrive/New_dataset/train.sent\n",
            "/content/drive/MyDrive/New_dataset/train.pointer\n",
            "/content/drive/MyDrive/New_dataset/train_bert.sent\n",
            "/content/drive/MyDrive/New_dataset/train_bert.pointer\n",
            "/content/drive/MyDrive/New_dataset/train_bert.pos\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/drive/My Drive/New_dataset/helper.py\" /content/drive/MyDrive/New_dataset/train.sent /content/drive/MyDrive/New_dataset/train.pointer /content/drive/MyDrive/New_dataset/train_bert.sent /content/drive/MyDrive/New_dataset/train_bert.pointer /content/drive/MyDrive/New_dataset/train_bert.pos "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/My Drive/New_dataset/helper.py\" /content/drive/MyDrive/New_dataset/dev.sent /content/drive/MyDrive/New_dataset/dev.pointer /content/drive/MyDrive/New_dataset/dev_bert.sent /content/drive/MyDrive/New_dataset/dev_bert.pointer /content/drive/MyDrive/New_dataset/dev_bert.pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwwwETpE4Qri",
        "outputId": "d5ec1dc4-0142-4536-bb6c-4f305c107ab6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "/content/drive/MyDrive/New_dataset/dev.sent\n",
            "/content/drive/MyDrive/New_dataset/dev.pointer\n",
            "/content/drive/MyDrive/New_dataset/dev_bert.sent\n",
            "/content/drive/MyDrive/New_dataset/dev_bert.pointer\n",
            "/content/drive/MyDrive/New_dataset/dev_bert.pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/My Drive/New_dataset/helper.py\" /content/drive/MyDrive/New_dataset/test.sent /content/drive/MyDrive/New_dataset/test.pointer /content/drive/MyDrive/New_dataset/test_bert.sent /content/drive/MyDrive/New_dataset/test_bert.pointer /content/drive/MyDrive/New_dataset/test_bert.pos "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJv7__zl4Q1w",
        "outputId": "30235e7a-044d-4f15-bba4-06281922973b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "/content/drive/MyDrive/New_dataset/test.sent\n",
            "/content/drive/MyDrive/New_dataset/test.pointer\n",
            "/content/drive/MyDrive/New_dataset/test_bert.sent\n",
            "/content/drive/MyDrive/New_dataset/test_bert.pointer\n",
            "/content/drive/MyDrive/New_dataset/test_bert.pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IRouZxg3u4oE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49b34f0-33a2-45e9-e544-c6e8a160c3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "['/content/drive/My Drive/New_dataset/matbert_ptrnet_decoder.py', '0', '1023', 'train', '32', '50', '0', '0', '0']\n",
            "100  \t  10  \t  0.5  \t  AspectFirst  \t  Random\n",
            "32  \t  50\n",
            "LSTM\n",
            "loading data......\n",
            "No. of sentences:  3427\n",
            "No. of sentences:  1096\n",
            "Training data size:  3379\n",
            "Development data size:  1096\n",
            "preparing vocabulary......\n",
            "getting pos tags......\n",
            "vocab length:  5180\n",
            "/content/drive/My Drive/New_dataset/w2v.txt\n",
            "embed dictionary length:  1224\n",
            "Training started......\n",
            "106\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Parameters size:  6555513\n",
            "Seq2SeqModel(\n",
            "  (encoder): Encoder(\n",
            "    (bert_vec): BERT(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (pos_embeddings): POSEmbeddings(\n",
            "      (embeddings): Embedding(44, 25, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (lstm): LSTM(793, 150, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (w): Linear(in_features=1200, out_features=300, bias=True)\n",
            "    (attention1): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (attention2): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (lstm): LSTMCell(1800, 300)\n",
            "    (ap_first_pointer_lstm): LSTM(600, 150, batch_first=True, bidirectional=True)\n",
            "    (op_second_pointer_lstm): LSTM(900, 150, batch_first=True, bidirectional=True)\n",
            "    (ap_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (ap_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (sent_lin): Linear(in_features=1500, out_features=7, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "weight factor:  1.0\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "Epoch:  1\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  4.179641016249387\n",
            "Training time:  0:00:28.142965\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.844480\n",
            "1191\n",
            "1102  \t  1246  \t  950\n",
            "P:  0.862\n",
            "R:  0.762\n",
            "F1:  0.8091993135809084\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "100% 106/106 [00:28<00:00,  3.73it/s]\n",
            "Training loss:  2.139426500167487\n",
            "Training time:  0:00:28.432933\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.94it/s]\n",
            "Prediction time:  0:00:11.910318\n",
            "1944\n",
            "1134  \t  1246  \t  1016\n",
            "P:  0.896\n",
            "R:  0.815\n",
            "F1:  0.8537815076089401\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  1.896077831398766\n",
            "Training time:  0:00:27.856290\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.811820\n",
            "2750\n",
            "1140  \t  1246  \t  1019\n",
            "P:  0.894\n",
            "R:  0.818\n",
            "F1:  0.8541491986908899\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "100% 106/106 [00:27<00:00,  3.85it/s]\n",
            "Training loss:  1.760598989027851\n",
            "Training time:  0:00:27.548228\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.810823\n",
            "1769\n",
            "1111  \t  1246  \t  1031\n",
            "P:  0.928\n",
            "R:  0.827\n",
            "F1:  0.8748408944574309\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "100% 106/106 [00:27<00:00,  3.83it/s]\n",
            "Training loss:  1.6615592961041432\n",
            "Training time:  0:00:27.664690\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.832623\n",
            "1673\n",
            "1119  \t  1246  \t  1037\n",
            "P:  0.927\n",
            "R:  0.832\n",
            "F1:  0.8769555975440002\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  1.5590015424872345\n",
            "Training time:  0:00:27.794258\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.839461\n",
            "1730\n",
            "1122  \t  1246  \t  1026\n",
            "P:  0.914\n",
            "R:  0.823\n",
            "F1:  0.8665540490604459\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "100% 106/106 [00:27<00:00,  3.80it/s]\n",
            "Training loss:  1.4982180944028891\n",
            "Training time:  0:00:27.925062\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.835169\n",
            "2946\n",
            "1127  \t  1246  \t  1042\n",
            "P:  0.925\n",
            "R:  0.836\n",
            "F1:  0.8782132272007054\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "100% 106/106 [00:28<00:00,  3.71it/s]\n",
            "Training loss:  1.4787887621600673\n",
            "Training time:  0:00:28.533306\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.837656\n",
            "1946\n",
            "1128  \t  1246  \t  1034\n",
            "P:  0.917\n",
            "R:  0.83\n",
            "F1:  0.8711036175829419\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  9\n",
            "100% 106/106 [00:27<00:00,  3.83it/s]\n",
            "Training loss:  1.4219664734489512\n",
            "Training time:  0:00:27.677879\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.827754\n",
            "2438\n",
            "1150  \t  1246  \t  1040\n",
            "P:  0.904\n",
            "R:  0.835\n",
            "F1:  0.868113517538343\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  10\n",
            "100% 106/106 [00:27<00:00,  3.83it/s]\n",
            "Training loss:  1.3521256295015227\n",
            "Training time:  0:00:27.668493\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.868355\n",
            "1502\n",
            "1131  \t  1246  \t  1049\n",
            "P:  0.927\n",
            "R:  0.842\n",
            "F1:  0.8826251527661617\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  11\n",
            "100% 106/106 [00:27<00:00,  3.80it/s]\n",
            "Training loss:  1.3223914498428129\n",
            "Training time:  0:00:27.859088\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.837496\n",
            "1779\n",
            "1128  \t  1246  \t  1055\n",
            "P:  0.935\n",
            "R:  0.847\n",
            "F1:  0.8887952772289598\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  12\n",
            "100% 106/106 [00:27<00:00,  3.83it/s]\n",
            "Training loss:  1.280068448410844\n",
            "Training time:  0:00:27.650524\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.828746\n",
            "1888\n",
            "1127  \t  1246  \t  1038\n",
            "P:  0.921\n",
            "R:  0.833\n",
            "F1:  0.8748419671923057\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  13\n",
            "100% 106/106 [00:27<00:00,  3.85it/s]\n",
            "Training loss:  1.2362609095168564\n",
            "Training time:  0:00:27.508670\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.823988\n",
            "1859\n",
            "1183  \t  1246  \t  1069\n",
            "P:  0.904\n",
            "R:  0.858\n",
            "F1:  0.880197607182201\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  14\n",
            "100% 106/106 [00:28<00:00,  3.75it/s]\n",
            "Training loss:  1.2152394680482037\n",
            "Training time:  0:00:28.252110\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.816245\n",
            "2027\n",
            "1139  \t  1246  \t  1046\n",
            "P:  0.918\n",
            "R:  0.839\n",
            "F1:  0.8771488419628761\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  15\n",
            "100% 106/106 [00:27<00:00,  3.79it/s]\n",
            "Training loss:  1.1923832676883013\n",
            "Training time:  0:00:27.981529\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.842269\n",
            "1965\n",
            "1174  \t  1246  \t  1071\n",
            "P:  0.912\n",
            "R:  0.86\n",
            "F1:  0.8851239619392598\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  16\n",
            "100% 106/106 [00:27<00:00,  3.84it/s]\n",
            "Training loss:  1.1448025127064507\n",
            "Training time:  0:00:27.628610\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.846416\n",
            "1833\n",
            "1175  \t  1246  \t  1078\n",
            "P:  0.917\n",
            "R:  0.865\n",
            "F1:  0.890541093716481\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  17\n",
            "100% 106/106 [00:27<00:00,  3.85it/s]\n",
            "Training loss:  1.1235306167377617\n",
            "Training time:  0:00:27.533638\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.867866\n",
            "1954\n",
            "1201  \t  1246  \t  1099\n",
            "P:  0.915\n",
            "R:  0.882\n",
            "F1:  0.8982427412142107\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  18\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  1.087095505224084\n",
            "Training time:  0:00:28.129290\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.854114\n",
            "1781\n",
            "1161  \t  1246  \t  1073\n",
            "P:  0.924\n",
            "R:  0.861\n",
            "F1:  0.8915662600590682\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  19\n",
            "100% 106/106 [00:27<00:00,  3.79it/s]\n",
            "Training loss:  1.0326817072225067\n",
            "Training time:  0:00:27.979591\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.858801\n",
            "2014\n",
            "1207  \t  1246  \t  1103\n",
            "P:  0.914\n",
            "R:  0.885\n",
            "F1:  0.8993069660497818\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  20\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  1.011041466357573\n",
            "Training time:  0:00:28.122827\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.92it/s]\n",
            "Prediction time:  0:00:11.989654\n",
            "1675\n",
            "1192  \t  1246  \t  1093\n",
            "P:  0.917\n",
            "R:  0.877\n",
            "F1:  0.8966365823617916\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  21\n",
            "100% 106/106 [00:27<00:00,  3.82it/s]\n",
            "Training loss:  0.9619143191935882\n",
            "Training time:  0:00:27.771922\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.94it/s]\n",
            "Prediction time:  0:00:11.894104\n",
            "1647\n",
            "1204  \t  1246  \t  1090\n",
            "P:  0.905\n",
            "R:  0.875\n",
            "F1:  0.8897959133615528\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  22\n",
            "100% 106/106 [00:27<00:00,  3.90it/s]\n",
            "Training loss:  0.936424841577152\n",
            "Training time:  0:00:27.177482\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.818148\n",
            "1743\n",
            "1226  \t  1246  \t  1110\n",
            "P:  0.905\n",
            "R:  0.891\n",
            "F1:  0.898058247420246\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  23\n",
            "100% 106/106 [00:27<00:00,  3.84it/s]\n",
            "Training loss:  0.901019626912081\n",
            "Training time:  0:00:27.603455\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.825000\n",
            "1702\n",
            "1215  \t  1246  \t  1110\n",
            "P:  0.914\n",
            "R:  0.891\n",
            "F1:  0.9020723233152829\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  24\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  0.893218328086835\n",
            "Training time:  0:00:27.787970\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.864066\n",
            "1752\n",
            "1214  \t  1246  \t  1097\n",
            "P:  0.904\n",
            "R:  0.88\n",
            "F1:  0.8918699136927821\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  25\n",
            "100% 106/106 [00:27<00:00,  3.84it/s]\n",
            "Training loss:  0.870302531095046\n",
            "Training time:  0:00:27.628297\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.840117\n",
            "1739\n",
            "1227  \t  1246  \t  1115\n",
            "P:  0.909\n",
            "R:  0.895\n",
            "F1:  0.9017387738041631\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  26\n",
            "100% 106/106 [00:27<00:00,  3.86it/s]\n",
            "Training loss:  0.8369877268120928\n",
            "Training time:  0:00:27.445507\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.827233\n",
            "1976\n",
            "1223  \t  1246  \t  1115\n",
            "P:  0.912\n",
            "R:  0.895\n",
            "F1:  0.9031996709752967\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  27\n",
            "100% 106/106 [00:27<00:00,  3.83it/s]\n",
            "Training loss:  0.8321166204394035\n",
            "Training time:  0:00:27.698207\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.851856\n",
            "1730\n",
            "1207  \t  1246  \t  1103\n",
            "P:  0.914\n",
            "R:  0.885\n",
            "F1:  0.8993069660497818\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  28\n",
            "100% 106/106 [00:27<00:00,  3.87it/s]\n",
            "Training loss:  0.7814049561912159\n",
            "Training time:  0:00:27.390716\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.826247\n",
            "1691\n",
            "1223  \t  1246  \t  1115\n",
            "P:  0.912\n",
            "R:  0.895\n",
            "F1:  0.9031996709752967\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  29\n",
            "100% 106/106 [00:27<00:00,  3.79it/s]\n",
            "Training loss:  0.7710894637231557\n",
            "Training time:  0:00:27.977658\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.836365\n",
            "1821\n",
            "1211  \t  1246  \t  1108\n",
            "P:  0.915\n",
            "R:  0.889\n",
            "F1:  0.901912896906575\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  30\n",
            "100% 106/106 [00:27<00:00,  3.79it/s]\n",
            "Training loss:  0.7562805824684646\n",
            "Training time:  0:00:27.932857\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.865742\n",
            "1978\n",
            "1248  \t  1246  \t  1130\n",
            "P:  0.905\n",
            "R:  0.907\n",
            "F1:  0.9061748145596972\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  31\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  0.752773755142149\n",
            "Training time:  0:00:28.147935\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.863871\n",
            "1920\n",
            "1219  \t  1246  \t  1124\n",
            "P:  0.922\n",
            "R:  0.902\n",
            "F1:  0.9119675406321459\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  32\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  0.7287890208217332\n",
            "Training time:  0:00:28.117636\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.842159\n",
            "1922\n",
            "1234  \t  1246  \t  1129\n",
            "P:  0.915\n",
            "R:  0.906\n",
            "F1:  0.9104838659605164\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  33\n",
            "100% 106/106 [00:27<00:00,  3.85it/s]\n",
            "Training loss:  0.6773554012179375\n",
            "Training time:  0:00:27.512165\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.827311\n",
            "1738\n",
            "1244  \t  1246  \t  1141\n",
            "P:  0.917\n",
            "R:  0.916\n",
            "F1:  0.9164658584464574\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  34\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  0.6745391957602411\n",
            "Training time:  0:00:28.140766\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.883222\n",
            "1797\n",
            "1232  \t  1246  \t  1128\n",
            "P:  0.916\n",
            "R:  0.905\n",
            "F1:  0.9104116172688408\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  35\n",
            "100% 106/106 [00:27<00:00,  3.79it/s]\n",
            "Training loss:  0.6361293272589738\n",
            "Training time:  0:00:27.973117\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.825944\n",
            "1669\n",
            "1218  \t  1246  \t  1124\n",
            "P:  0.923\n",
            "R:  0.902\n",
            "F1:  0.9123376573309028\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  36\n",
            "100% 106/106 [00:27<00:00,  3.80it/s]\n",
            "Training loss:  0.677214282020083\n",
            "Training time:  0:00:27.907912\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.831705\n",
            "1740\n",
            "1220  \t  1246  \t  1119\n",
            "P:  0.917\n",
            "R:  0.898\n",
            "F1:  0.9075425740686214\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  37\n",
            "100% 106/106 [00:27<00:00,  3.79it/s]\n",
            "Training loss:  0.6668414724463562\n",
            "Training time:  0:00:27.963078\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.846750\n",
            "1728\n",
            "1232  \t  1246  \t  1121\n",
            "P:  0.91\n",
            "R:  0.9\n",
            "F1:  0.9047618997547622\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  38\n",
            "100% 106/106 [00:27<00:00,  3.82it/s]\n",
            "Training loss:  0.6340427703733714\n",
            "Training time:  0:00:27.763498\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.93it/s]\n",
            "Prediction time:  0:00:11.962625\n",
            "1775\n",
            "1245  \t  1246  \t  1127\n",
            "P:  0.905\n",
            "R:  0.904\n",
            "F1:  0.9048574819457669\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  39\n",
            "100% 106/106 [00:27<00:00,  3.84it/s]\n",
            "Training loss:  0.6194319436502345\n",
            "Training time:  0:00:27.577634\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:12<00:00,  2.90it/s]\n",
            "Prediction time:  0:00:12.082670\n",
            "1725\n",
            "1236  \t  1246  \t  1129\n",
            "P:  0.913\n",
            "R:  0.906\n",
            "F1:  0.9097501964431938\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  40\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  0.5917301788785547\n",
            "Training time:  0:00:27.787980\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.94it/s]\n",
            "Prediction time:  0:00:11.921365\n",
            "1808\n",
            "1247  \t  1246  \t  1141\n",
            "P:  0.915\n",
            "R:  0.916\n",
            "F1:  0.9153630114387065\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  41\n",
            "100% 106/106 [00:27<00:00,  3.84it/s]\n",
            "Training loss:  0.6074379903949657\n",
            "Training time:  0:00:27.620806\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.830203\n",
            "1747\n",
            "1232  \t  1246  \t  1122\n",
            "P:  0.911\n",
            "R:  0.9\n",
            "F1:  0.9055690022567734\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  42\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  0.5942436796876619\n",
            "Training time:  0:00:27.850688\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.832233\n",
            "1716\n",
            "1222  \t  1246  \t  1114\n",
            "P:  0.912\n",
            "R:  0.894\n",
            "F1:  0.902755262416172\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  43\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  0.6044977737485238\n",
            "Training time:  0:00:27.831222\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.823506\n",
            "1667\n",
            "1209  \t  1246  \t  1100\n",
            "P:  0.91\n",
            "R:  0.883\n",
            "F1:  0.8961303412260145\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  44\n",
            "100% 106/106 [00:28<00:00,  3.77it/s]\n",
            "Training loss:  0.566903108695768\n",
            "Training time:  0:00:28.113633\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.822682\n",
            "1830\n",
            "1239  \t  1246  \t  1130\n",
            "P:  0.912\n",
            "R:  0.907\n",
            "F1:  0.9094567354353761\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  45\n",
            "100% 106/106 [00:28<00:00,  3.79it/s]\n",
            "Training loss:  0.5648329764745146\n",
            "Training time:  0:00:28.001886\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.828726\n",
            "1646\n",
            "1233  \t  1246  \t  1129\n",
            "P:  0.916\n",
            "R:  0.906\n",
            "F1:  0.9108511446499089\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  46\n",
            "100% 106/106 [00:27<00:00,  3.81it/s]\n",
            "Training loss:  0.5727745371185383\n",
            "Training time:  0:00:27.820623\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.823737\n",
            "1935\n",
            "1249  \t  1246  \t  1128\n",
            "P:  0.903\n",
            "R:  0.905\n",
            "F1:  0.9042084118264265\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  47\n",
            "100% 106/106 [00:27<00:00,  3.80it/s]\n",
            "Training loss:  0.5850852019381974\n",
            "Training time:  0:00:27.919970\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.828394\n",
            "1725\n",
            "1235  \t  1246  \t  1131\n",
            "P:  0.916\n",
            "R:  0.908\n",
            "F1:  0.9117291364679605\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  48\n",
            "100% 106/106 [00:27<00:00,  3.88it/s]\n",
            "Training loss:  0.5796754346844161\n",
            "Training time:  0:00:27.354221\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.94it/s]\n",
            "Prediction time:  0:00:11.920563\n",
            "1619\n",
            "1228  \t  1246  \t  1127\n",
            "P:  0.918\n",
            "R:  0.904\n",
            "F1:  0.9110751768845731\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  49\n",
            "100% 106/106 [00:27<00:00,  3.83it/s]\n",
            "Training loss:  0.5442994129404707\n",
            "Training time:  0:00:27.688764\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.96it/s]\n",
            "Prediction time:  0:00:11.844503\n",
            "1761\n",
            "1222  \t  1246  \t  1112\n",
            "P:  0.91\n",
            "R:  0.892\n",
            "F1:  0.9011345168732353\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  50\n",
            "100% 106/106 [00:27<00:00,  3.87it/s]\n",
            "Training loss:  0.5356572059527883\n",
            "Training time:  0:00:27.383392\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:11<00:00,  2.95it/s]\n",
            "Prediction time:  0:00:11.855826\n",
            "1763\n",
            "1255  \t  1246  \t  1130\n",
            "P:  0.9\n",
            "R:  0.907\n",
            "F1:  0.9036385395750057\n",
            "\n",
            "\n",
            "\n",
            "*******\n",
            "Best Epoch:  33\n",
            "Best Epoch Seed:  1056\n",
            "Best Dev F1:  0.916\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/drive/My Drive/New_dataset/matbert_ptrnet_decoder.py\" 0 1023 train 32 50 0 0 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nflzOhtgu4qJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318b9530-8d2a-43b9-d313-a2abd523cf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "['/content/drive/My Drive/New_dataset/matbert_ptrnet_decoder.py', '0', '1023', 'test', '32', '50', '0', '0', '0']\n",
            "loading word vectors......\n",
            "vocab size:  1224\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Seq2SeqModel(\n",
            "  (encoder): Encoder(\n",
            "    (bert_vec): BERT(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (pos_embeddings): POSEmbeddings(\n",
            "      (embeddings): Embedding(44, 25, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (lstm): LSTM(793, 150, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (w): Linear(in_features=1200, out_features=300, bias=True)\n",
            "    (attention1): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (attention2): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (lstm): LSTMCell(1800, 300)\n",
            "    (ap_first_pointer_lstm): LSTM(600, 150, batch_first=True, bidirectional=True)\n",
            "    (op_second_pointer_lstm): LSTM(900, 150, batch_first=True, bidirectional=True)\n",
            "    (ap_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (ap_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (sent_lin): Linear(in_features=1500, out_features=7, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "\n",
            "Test Results\n",
            "\n",
            "No. of sentences:  2192\n",
            "Test data size:  2192\n",
            "100% 69/69 [00:24<00:00,  2.82it/s]\n",
            "Prediction time:  0:00:24.475052\n",
            "2184\n",
            "1554  \t  1599  \t  1418\n",
            "For relation : Voltage\n",
            "P:  0.912\n",
            "R:  0.887\n",
            "F1:  0.899\n",
            "\n",
            "\n",
            "670\n",
            "438  \t  444  \t  406\n",
            "For relation : Capacity\n",
            "P:  0.927\n",
            "R:  0.914\n",
            "F1:  0.921\n",
            "\n",
            "\n",
            "82\n",
            "49  \t  53  \t  45\n",
            "For relation : Conductivity\n",
            "P:  0.918\n",
            "R:  0.849\n",
            "F1:  0.882\n",
            "\n",
            "\n",
            "409\n",
            "334  \t  333  \t  302\n",
            "For relation : Coulombic_Efficiency\n",
            "P:  0.904\n",
            "R:  0.907\n",
            "F1:  0.906\n",
            "\n",
            "\n",
            "120\n",
            "87  \t  86  \t  83\n",
            "For relation : Energy\n",
            "P:  0.954\n",
            "R:  0.965\n",
            "F1:  0.96\n",
            "\n",
            "\n",
            "Test size: 2192\n",
            "100% 69/69 [00:24<00:00,  2.85it/s]\n",
            "Prediction time:  0:00:24.227155\n",
            "3465\n",
            "2462  \t  2503  \t  2262\n",
            "P:  0.919\n",
            "R:  0.904\n",
            "F1:  0.911\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/drive/My Drive/New_dataset/matbert_ptrnet_decoder.py\" 0 1023 test 32 50 0 0 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MatBERT_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}